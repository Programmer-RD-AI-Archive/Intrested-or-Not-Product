{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_funtions import *\n",
    "from models.clf_and_conv1d import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory='./data/raw/',IMG_SIZE=224):\n",
    "    data = []\n",
    "    labels = {}\n",
    "    labels_idx = -1\n",
    "    for directory in os.listdir(directory):\n",
    "        labels_idx += 1\n",
    "        labels['./data/raw/' + directory + '/'] = [labels_idx,-1]\n",
    "    for label in tqdm(labels.keys()):\n",
    "        for file in tqdm(os.listdir(label)):\n",
    "            labels[label][1] += 1\n",
    "            img = cv2.imread(label + file)\n",
    "            img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n",
    "            data.append([np.array(transformations(np.array(img/255.0))),labels[label][0]])\n",
    "    np.random.shuffle(data)\n",
    "    X = []\n",
    "    y = []\n",
    "    for d in tqdm(data):\n",
    "        X.append(d[0])\n",
    "        y.append(d[1])\n",
    "    VAL_SPLIT = 125\n",
    "    X_train = X[:-VAL_SPLIT]\n",
    "    y_train = y[:-VAL_SPLIT]\n",
    "    X_test = X[-VAL_SPLIT:]\n",
    "    y_test = y[-VAL_SPLIT:]\n",
    "    for key,val in zip(labels,keys(),labels.values()):\n",
    "        print(key)\n",
    "        print(val)\n",
    "    return torch.tensor(X_train),torch.tensor(y_train),torch.tensor(X_test),torch.tensor(y_test),labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,y_train,X_test,y_test = load_data()\n",
    "# torch.save(X_train,'./data/cleaned/X_train.pt')\n",
    "# torch.save(X_train,'./data/cleaned/X_train.pth')\n",
    "# torch.save(y_train,'./data/cleaned/y_train.pt')\n",
    "# torch.save(y_train,'./data/cleaned/y_train.pth')\n",
    "# torch.save(X_test,'./data/cleaned/X_test.pt')\n",
    "# torch.save(X_test,'./data/cleaned/X_test.pth')\n",
    "# torch.save(y_test,'./data/cleaned/y_test.pt')\n",
    "# torch.save(y_test,'./data/cleaned/y_test.pth')\n",
    "\n",
    "X_train = torch.load('./data/cleaned/X_train.pt')\n",
    "y_train = torch.load('./data/cleaned/y_train.pt')\n",
    "X_test = torch.load('./data/cleaned/X_test.pt')\n",
    "y_test = torch.load('./data/cleaned/y_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'Intrested-or-Not-Intrested-In-A-Product'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = Help_Funcs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mranuga-d\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">Clf_and_Conv1d</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ranuga-d/Intrested-or-Not-Intrested-In-A-Product\" target=\"_blank\">https://wandb.ai/ranuga-d/Intrested-or-Not-Intrested-In-A-Product</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ranuga-d/Intrested-or-Not-Intrested-In-A-Product/runs/2amuqbgy\" target=\"_blank\">https://wandb.ai/ranuga-d/Intrested-or-Not-Intrested-In-A-Product/runs/2amuqbgy</a><br/>\n",
       "                Run data is saved locally in <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/Competions/Intrested-or-Not-Product-V2/wandb/run-20210712_131737-2amuqbgy</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model = Clf_and_Conv1d()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "criterion = BCELoss()\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "wandb.init(project=PROJECT_NAME,name='Clf_and_Conv1d')\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for idx in range(0,len(X_train),batch_size):\n",
    "        X_batch = X_train[idx:idx+batch_size].to(device)\n",
    "        y_batch = y_train[idx:idx+batch_size].to(device)\n",
    "        model.to(device)\n",
    "        preds = model(X_batch.float())\n",
    "        loss = criterion(preds.view(-1,1).to(device).float(),y_batch.view(-1,1).float())\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({'loss':loss.item()})\n",
    "        wandb.log({'val_loss':hp.get_loss(model.to('cpu'),X_test,y_test,criterion)})\n",
    "        wandb.log({'accuracy':hp.get_accuracy_preds(preds,y_batch)})\n",
    "        wandb.log({'val_accuracy':hp.get_accuracy(model.to('cpu'),X_test,y_test)})\n",
    "        model.to(device)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.get_accuracy_preds(preds,y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.clf_model import *\n",
    "model = Clf()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "criterion = BCELoss()\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "wandb.init(project=PROJECT_NAME,name='Clf')\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for idx in range(0,len(X_train),batch_size):\n",
    "        X_batch = X_train[idx:idx+batch_size].to(device)\n",
    "        y_batch = y_train[idx:idx+batch_size].to(device)\n",
    "        model.to(device)\n",
    "        preds = model(X_batch.float())\n",
    "        loss = criterion(preds.view(-1,1).to(device).float(),y_batch.view(-1,1).float())\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({'loss':loss.item()})\n",
    "        wandb.log({'val_loss':hp.get_loss(model.to('cpu'),X_test,y_test,criterion)})\n",
    "        wandb.log({'accuracy':hp.get_accuracy_preds(preds,y_batch)})\n",
    "        wandb.log({'val_accuracy':hp.get_accuracy(model.to('cpu'),X_test,y_test)})\n",
    "        model.to(device)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cnn import *\n",
    "model = CNN()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "criterion = BCELoss()\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "wandb.init(project=PROJECT_NAME,name='CNN')\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for idx in range(0,len(X_train),batch_size):\n",
    "        X_batch = X_train[idx:idx+batch_size].to(device)\n",
    "        y_batch = y_train[idx:idx+batch_size].to(device)\n",
    "        model.to(device)\n",
    "        preds = model(X_batch.float())\n",
    "        loss = criterion(preds.view(-1,1).to(device).float(),y_batch.view(-1,1).float())\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({'loss':loss.item()})\n",
    "        wandb.log({'val_loss':hp.get_loss(model.to('cpu'),X_test,y_test,criterion)})\n",
    "        wandb.log({'accuracy':hp.get_accuracy_preds(preds,y_batch)})\n",
    "        wandb.log({'val_accuracy':hp.get_accuracy(model.to('cpu'),X_test,y_test)})\n",
    "        model.to(device)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tl_models import *\n",
    "model = TL_Model()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "criterion = BCELoss()\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "wandb.init(project=PROJECT_NAME,name='TL_Model')\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for idx in range(0,len(X_train),batch_size):\n",
    "        X_batch = X_train[idx:idx+batch_size].to(device)\n",
    "        y_batch = y_train[idx:idx+batch_size].to(device)\n",
    "        model.to(device)\n",
    "        preds = model(X_batch.float())\n",
    "        loss = criterion(preds.view(-1,1).to(device).float(),y_batch.view(-1,1).float())\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({'loss':loss.item()})\n",
    "        wandb.log({'val_loss':hp.get_loss(model.to('cpu'),X_test,y_test,criterion)})\n",
    "        wandb.log({'accuracy':hp.get_accuracy_preds(preds,y_batch)})\n",
    "        wandb.log({'val_accuracy':hp.get_accuracy(model.to('cpu'),X_test,y_test)})\n",
    "        model.to(device)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tl_models import *\n",
    "model = TL_Model_2()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "criterion = BCELoss()\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "wandb.init(project=PROJECT_NAME,name='TL_Model_2')\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for idx in range(0,len(X_train),batch_size):\n",
    "        X_batch = X_train[idx:idx+batch_size].to(device)\n",
    "        y_batch = y_train[idx:idx+batch_size].to(device)\n",
    "        model.to(device)\n",
    "        preds = model(X_batch.float())\n",
    "        loss = criterion(preds.view(-1,1).to(device).float(),y_batch.view(-1,1).float())\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({'loss':loss.item()})\n",
    "        wandb.log({'val_loss':hp.get_loss(model.to('cpu'),X_test,y_test,criterion)})\n",
    "        wandb.log({'accuracy':hp.get_accuracy_preds(preds,y_batch)})\n",
    "        wandb.log({'val_accuracy':hp.get_accuracy(model.to('cpu'),X_test,y_test)})\n",
    "        model.to(device)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "210f9608a45c0278a93c9e0b10db32a427986ab48cfc0d20c139811eb78c4bbc"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}